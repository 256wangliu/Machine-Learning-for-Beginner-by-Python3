# BPNN Theory
 
#### 理论推导

+ **符号说明**

    1. **神经网络的层数**m，也就是包括m-2个隐层；
    2. **输入层**定义为I，其节点数等于样本的输入维度数ni；
    
       **隐层**定义为Hh，h为1到m-2，每一个隐层的节点数为Nh；
       
       **输出层**为O，其节点数等于样本的输出维度数No；
       
    3. 每一个隐层的**权重**为Ws，s为0到m-3，ws矩阵的大小为g\*t, g为该隐层前一层的节点数，t为该隐层的节点数；
    
       对应的**偏置**为Bs，s为0到m-3，ws矩阵的大小为1\*t, t为该隐层的节点数；
    
    4. 隐层的**激活函数**Ah，h为1到m-2。每一层的激活函数可以不同，但是大多数情形下设置为相同的；
    
       常用的激活函数：Sigmoid，Tanh，ReLU。选择激活函数时一定要注意：**激活函数的输出尺度一定要和样本的输出数据是同一尺度。例如Sigmoid的输出是0-1，因此样本的输出也应该在0-1之间。



+ **正向传播**



+ **反向传播**


    + **回归**
    

    + **分类**

 

 
 
  
