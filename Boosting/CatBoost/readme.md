# CatBoost介绍

**CatBoost**是俄罗斯的搜索巨头Yandex在2017年开源的机器学习库，是**Gradient Boosting**(**梯度提升**) + **Categorical Features**(**类别型特征**)。类似于LightGBM，也是基于梯度提升决策树的机器学习框架。[详情参见](https://tech.yandex.com/catboost/)。

### 1，CatBoost介绍

以下内容主要翻译自[论文](http://learningsys.org/nips17/assets/papers/paper_11.pdf)


### 论文题目：

**CatBoost: gradient boosting with categorical features support**

##### 作者：

**Anna Veronika Dorogush, Vasily Ershov, Andrey Gulin**

##### 摘要：

本文介绍了一个新的开源的梯度提升库——CatBoost，它可以很好地处理类别型特征，并且在许多流行的公共数据集上，其性能超越了目前同样基于梯度提升的其他算法。这个库训练采用GPU，评分采用CPU，针对许多不同尺寸的数据样本集合，速度都明显快于其他梯度提升库。

### 1 引言

梯度提升是一种强大的机器学习算法，在许多不同领域的应用中都能获得很好的结果。多年来，在解决具有异构特征、噪声和复杂依赖关系的数据的学习问题时，例如web搜索，推荐系统、天气预报以及其他方面的问题，它都作为首选方法。通过对函数空间中的梯度下降相对应的贪婪过程建模理论，可以解释如何通过迭代组合模型(弱预测器)来构建强预测器是可行的。

大多数流行的梯度提升算法利用决策树作为基本预测器。对于数值型特征使用决策树很方便，但是实际中，许多数据集包括类别型特征，这些特征对预测也很重要。类别型特征具有离散的值，并且这些值之间的比较(例如用户的ID，城市的名称)是没意义的，梯度提升算法中处理这类特征的最常用的方法就是在训练之前，也就是数据预处理阶段，将这些特征的值转换为数字。

本文提出了一种新的可以很好的处理类别型特征的梯度提升算法，并且该算法的改进之处就在于在训练的时候处理这些特征，而不是在数据预处理阶段。该算法的另一个优点是使用新的方法计算叶子节点的值来生成树，并且这种计算方式有助于减少过拟合。


在许多不同的流行数据集上的，本文算法的性能均优于目前最先进的梯度提升算法库，例如GBDT，XGBoost，LightGBM，H2O。这个算法命名为CatBoost（“分类提升”），源码已经开源。

CatBoost具有CPU和GPU实现。GPU实现允许很多
比两种最新的开源GBDT GPU实现更快的培训和更快，
XGBoost和LightGBM，在相似大小的集合上。该库还具有快速的CPU评分
实现，在
大小相似。

#### 1.1 类别型特征

   类别型特征，也就是具有离散值的特征，例如类似收入(高，低)、成绩(优秀，良好，差)、天气(晴天，阴天)这样用类别值表示的特征。可以通过数字编码来处理这类特征，也就是每个类别值对应一个数字。其中独热编码是广泛应用的一种处理方式，可以在数据预处理阶段或者训练阶段使用，CatBoost就是在训练阶段才使用的。


#### 2，CatBoost的优点(官宣)

1. 性能卓越：在性能方面可以匹敌任何先进的机器学习算法；

1. 鲁棒性/强健性：它减少了对很多超参数调优的需求，并降低了过度拟合的机会，这也使得模型变得更加具有通用性。

1. 易于使用：提供与scikit集成的Python接口，以及R和命令行界面；

1. 实用：特征值可以为字符串或者数字，无需将字符串经过编码；

1. 可扩展：支持自定义损失函数；


### 2，CatBoost程序文件
