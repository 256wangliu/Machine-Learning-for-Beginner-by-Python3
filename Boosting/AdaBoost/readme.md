## AdaBoost

* **AdaBoost初识**

这个方法主要涉及到2个权重集合：

1. **样本的权重集合Y**：每个样本都对应一个权重。 在构建第一个弱模型之前，所有的训练样本的权重是一样的。第一个模型完成后，要加大那些被这个模型错误分类(分类问题)、或者说预测真实差值较大(回归问题)的样本的权重。依次迭代，最终构建多个弱模型。每个弱模型所对应的训练数据集样本是一样的，只是数据集中的样本权重是不一样的。

2. **弱模型的权重集合M**：得到的每个弱模型都对应一个权重。这个权重依赖于每个弱模型的精度(分类：正确率，回归：MSE)。精度越高的模型，其权重也就越大，在最终集成结果时，其话语权也就越大。

* **AdaBoost步骤**

  * **分类问题**
  
   1. 训练数据集Data={(X1, Y1), (X2, Y2),……(Xn, Yn)}，每个数据集样本的初始权重为1/n。
   2. 
   
   
* **AdaBoost答疑**   
   1. 这个弱模型可以是什么？
   
   答：经常用的就是单层的决策树，也称为决策树桩(Decision Stump)，例如单层的CART。其实这个层数也是参数，需要交叉验证得到最好的。
   
   2. 增加的样本权重如何在下一个模型训练时体现出作用？
   
   答：一种方式是通过抽样，来增加这些样本被选中的可能性；二是
  
