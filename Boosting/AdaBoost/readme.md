## AdaBoost

* **AdaBoost初识**

这个方法主要涉及到2个权重集合：

1. **样本的权重集合Y**：每个样本都对应一个权重。 在构建第一个弱模型之前，所有的训练样本的权重是一样的。第一个模型完成后，要加大那些被这个模型错误分类(分类问题)、或者说预测真实差值较大(回归问题)的样本的权重。依次迭代，最终构建多个弱模型。每个弱模型所对应的训练数据集样本是一样的，只是数据集中的样本权重是不一样的。

2. **弱模型的权重集合M**：得到的每个弱模型都对应一个权重。这个权重依赖于每个弱模型的精度(分类：正确率，回归：MSE)。精度越高的模型，其权重也就越大，在最终集成结果时，其话语权也就越大。

* **AdaBoost步骤**

  * **分类问题**
  
   1. 训练数据集Data={(X1, Y1), (X2, Y2),……(Xn, Yn)}，每个数据集样本的初始权重为1/n。
   2. 
