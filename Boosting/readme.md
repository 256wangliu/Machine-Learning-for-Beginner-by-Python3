# Boosting 介绍

+ **Boosting思想**

   1. 每一次都根据上一次训练得到的模型结果，调整数据集样本分布，然后再生成下一个模型；
   2. 根据所有模型的结果集成最终的结果；
  
+ **集成方式**

   1. 每个模型的重要度作为每个模型结果的权重，然后加权计算得出结果。
   
 可以看出Boosting中生成多个模型的方式并不是和Bagging一样并行生成，而是串行生成，因此也决定了多个模型结果的集成是**串行集成**。如何来调整样本分布以及如何结算模型的重要度，不同方法有不同的定义，详情参见具体方法。
+ **代表方法**

   + **AdaBoost**
   
   + **GBDT**
   
   + **XGBoost**


